{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpdbs9409/WST-T01/blob/main/CDS4004_ProjectCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required library"
      ],
      "metadata": {
        "id": "lqwYaBHuWFxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "from networkx.algorithms.community.centrality import girvan_newman\n",
        "from networkx.algorithms.community import kernighan_lin_bisection, partition_quality, modularity\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "hwC9sG8qWNZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetching Data from website"
      ],
      "metadata": {
        "id": "IylLKd17V0xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Request the web page\n",
        "site = \"https://www.transfermarkt.com/premier-league/transfers/wettbewerb/GB1/plus/?saison_id=2023&s_w=&leihe=1&intern=0/\"\n",
        "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
        "req = Request(site, headers=hdr)\n",
        "page = urlopen(req)\n",
        "soup = BeautifulSoup(page, 'html.parser')\n",
        "\n",
        "# Initialize dictionaries to store all 'in' and 'out' players for each team\n",
        "in_players = {}\n",
        "out_players = {}\n",
        "\n",
        "# Iterate through each team's name tag to collect 'in' and 'out' players\n",
        "for team_headline in soup.find_all('h2', class_='content-box-headline'):\n",
        "    team_name_tag = team_headline.find('a', title=True)\n",
        "    if not team_name_tag:\n",
        "        continue\n",
        "    team_name = team_name_tag.get('title')\n",
        "\n",
        "    # Find 'in' players table\n",
        "    in_table_div = team_headline.find_next_sibling('div', class_='responsive-table')\n",
        "    in_table = in_table_div.find('table') if in_table_div else None\n",
        "    if in_table:\n",
        "        in_players[team_name] = [(row.find_all('td')[0].text.strip(), row.find_all('td')[-1].text.strip()) for row in in_table.find_all('tr')[1:]]\n",
        "\n",
        "    # Find 'out' players table\n",
        "    out_table_div = in_table_div.find_next_sibling('div', class_='responsive-table') if in_table_div else None\n",
        "    out_table = out_table_div.find('table') if out_table_div else None\n",
        "    if out_table:\n",
        "        out_players[team_name] = [(row.find_all('td')[0].text.strip(), row.find_all('td')[-1].text.strip()) for row in out_table.find_all('tr')[1:]]\n",
        "\n",
        "# Create a list to store transfer details\n",
        "transfers_list = []\n",
        "\n",
        "# Compare 'in' players of each team with 'out' players of all other teams\n",
        "for to_team, players_in in in_players.items():\n",
        "    for player, in_fee in players_in:\n",
        "        for from_team, players_out in out_players.items():\n",
        "            for player_out, out_fee in players_out:\n",
        "                if player == player_out and from_team != to_team:\n",
        "                    transfers_list.append({\n",
        "                        'Player Name': player,\n",
        "                        'From Team': from_team,\n",
        "                        'To Team': to_team,\n",
        "                        'Fee In': in_fee,\n",
        "\n",
        "                    })\n",
        "\n",
        "# Print out the transfer list\n",
        "for transfer in transfers_list:\n",
        "    print(f\"Player Name: {transfer['Player Name']}, From Team: {transfer['From Team']}, To Team: {transfer['To Team']}, Fee: {transfer['Fee In']}\")\n"
      ],
      "metadata": {
        "id": "yvSnc8vocgiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transfers_list)"
      ],
      "metadata": {
        "id": "MDTBKFyJgXJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network Construction"
      ],
      "metadata": {
        "id": "AI3oWvirRV6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(transfers_list)\n",
        "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
        "\n",
        "def clean_player_name(name):\n",
        "  # Splitting the name by spaces to isolate the last name\n",
        "  parts = name.split()\n",
        "  # Getting the last name (assuming the last word is the last name)\n",
        "  last_name = parts[-1]  # -1 because the last part is the short name's last name\n",
        "  # Calculating the length to remove: length of the last name + 3 (for initial, period, and space)\n",
        "  length_to_remove = len(last_name) + 3\n",
        "  # Removing the last 'length_to_remove' characters\n",
        "  cleaned_name = name[:-length_to_remove]\n",
        "\n",
        "  return cleaned_name\n",
        "\n",
        "def check_loan(fee):\n",
        "    if 'loan' in fee.lower():\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "df['player_name'] = df['player_name'].apply(clean_player_name)\n",
        "\n",
        "#Add a column to store if a transfer is loan or not\n",
        "df['loan'] = df['fee_in'].apply(check_loan)\n",
        "\n",
        "#Replacing the loaning date to a assumed value\n",
        "df['fee_in'] = df['fee_in'].apply(lambda x: '€0.00m' if 'free' in x else ('€3.00m' if '€' not in x else x))\n",
        "\n",
        "df[df['fee_in'] == '€3.00m']"
      ],
      "metadata": {
        "id": "ebGZGXPZySHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.DiGraph()\n",
        "pos = {\n",
        "    'Arsenal FC': (1, 10),\n",
        "    'Chelsea FC': (1, 9),\n",
        "    'Manchester City': (1, 8),\n",
        "    'Manchester United': (1, 7),\n",
        "    'Tottenham Hotspur': (1, 6),\n",
        "    'Liverpool FC': (1, 5),\n",
        "    'Everton FC': (2, 10),\n",
        "    'Fulham FC': (2, 9),\n",
        "    'Brentford FC': (2, 8),\n",
        "    'Wolverhampton Wanderers': (2, 7),\n",
        "    'Sheffield United': (2, 6),\n",
        "    'Nottingham Forest': (2, 5),\n",
        "    'Burnley FC': (2, 4),\n",
        "    'Brighton & Hove Albion': (2, 3),\n",
        "    'Crystal Palace': (3, 10),\n",
        "    'Luton Town': (3, 9),\n",
        "    'West Ham United': (3, 8),\n",
        "    'Newcastle United': (3, 7),\n",
        "    'Aston Villa': (3, 6),\n",
        "    'AFC Bournemouth': (3, 5)\n",
        "}\n",
        "\n",
        "df2 = pd.DataFrame()\n",
        "df2['combine'] = df['from_team'].combine_first(df['to_team'])\n",
        "missed_team = {'combine':'Crystal Palace'}\n",
        "df2 = pd.concat([df2, pd.DataFrame([missed_team])], ignore_index=True)\n",
        "\n",
        "for team in df2['combine'].unique():\n",
        "  G.add_node(str(team))\n",
        "\n",
        "for i in range(len(df)):\n",
        "  weights = re.search(r'(?:€)(\\d+\\.\\d+)(?:m)', df['fee_in'][i])\n",
        "  G.add_edge(df['from_team'][i], df['to_team'][i], weight=weights.group(1), edge_labels=weights.group(1))\n",
        "\n",
        "nx.draw(G, with_labels=True, hide_ticks=False, pos=pos)"
      ],
      "metadata": {
        "id": "gikQ-h-U3k42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.DiGraph()\n",
        "pos = {\n",
        "    'Arsenal FC': (1, 10),\n",
        "    'Chelsea FC': (1, 9),\n",
        "    'Manchester City': (1, 8),\n",
        "    'Manchester United': (1, 7),\n",
        "    'Tottenham Hotspur': (1, 6),\n",
        "    'Liverpool FC': (1, 5),\n",
        "    'Everton FC': (2, 10),\n",
        "    'Fulham FC': (2, 9),\n",
        "    'Brentford FC': (2, 8),\n",
        "    'Wolverhampton Wanderers': (2, 7),\n",
        "    'Sheffield United': (2, 6),\n",
        "    'Nottingham Forest': (2, 5),\n",
        "    'Burnley FC': (2, 4),\n",
        "    'Brighton & Hove Albion': (2, 3),\n",
        "    'Crystal Palace': (3, 10),\n",
        "    'Luton Town': (3, 9),\n",
        "    'West Ham United': (3, 8),\n",
        "    'Newcastle United': (3, 7),\n",
        "    'Aston Villa': (3, 6),\n",
        "    'AFC Bournemouth': (3, 5)\n",
        "}\n",
        "\n",
        "df2 = pd.DataFrame()\n",
        "df2['combine'] = df['from_team'].combine_first(df['to_team'])\n",
        "missed_team = {'combine':'Crystal Palace'}\n",
        "df2 = pd.concat([df2, pd.DataFrame([missed_team])], ignore_index=True)\n",
        "\n",
        "for team in df2['combine'].unique():\n",
        "  G.add_node(str(team))\n",
        "\n",
        "for i in range(len(df)):\n",
        "  weights = re.search(r'(?:€)(\\d+\\.\\d+)(?:m)', df['fee_in'][i])\n",
        "  if weights:  # Checking if the search was successful\n",
        "      G.add_edge(df['from_team'][i], df['to_team'][i], weight=float(weights.group(1)), edge_labels=weights.group(1))\n",
        "\n",
        "# Drawing the graph\n",
        "nx.draw(G, with_labels=True, pos=pos, node_color='lightblue', edge_color='gray')\n",
        "\n",
        "# To show weights\n",
        "edge_labels = nx.get_edge_attributes(G, 'weight')\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bELjIIgvP-RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.DiGraph()\n",
        "pos = {\n",
        "    'Arsenal FC': (1, 10),\n",
        "    'Chelsea FC': (1, 9),\n",
        "    'Manchester City': (1, 8),\n",
        "    'Manchester United': (1, 7),\n",
        "    'Tottenham Hotspur': (1, 6),\n",
        "    'Liverpool FC': (1, 5),\n",
        "    'Everton FC': (2, 10),\n",
        "    'Fulham FC': (2, 9),\n",
        "    'Brentford FC': (2, 8),\n",
        "    'Wolverhampton Wanderers': (2, 7),\n",
        "    'Sheffield United': (2, 6),\n",
        "    'Nottingham Forest': (2, 5),\n",
        "    'Burnley FC': (2, 4),\n",
        "    'Brighton & Hove Albion': (2, 3),\n",
        "    'Crystal Palace': (3, 10),\n",
        "    'Luton Town': (3, 9),\n",
        "    'West Ham United': (3, 8),\n",
        "    'Newcastle United': (3, 7),\n",
        "    'Aston Villa': (3, 6),\n",
        "    'AFC Bournemouth': (3, 5)\n",
        "}\n",
        "\n",
        "df2 = pd.DataFrame()\n",
        "df2['combine'] = df['from_team'].combine_first(df['to_team'])\n",
        "missed_team = {'combine':'Crystal Palace'}\n",
        "df2 = pd.concat([df2, pd.DataFrame([missed_team])], ignore_index=True)\n",
        "\n",
        "for team in df2['combine'].unique():\n",
        "  G.add_node(str(team))\n",
        "\n",
        "for i in range(len(df)):\n",
        "  weights = re.search(r'(?:€)(\\d+\\.\\d+)(?:m)', df['fee_in'][i])\n",
        "  #print(weights.groups())\n",
        "  if weights:  # Checking if the search was successful\n",
        "      G.add_edge(df['from_team'][i], df['to_team'][i], weight=float(weights.group(1)), edge_labels=weights.group(1))\n",
        "      print(df['from_team'][i], df['to_team'][i])\n",
        "      print(G.get_edge_data(df['from_team'][i], df['to_team'][i]))\n",
        "\n",
        "# Adjusting edge label positions\n",
        "def adjust_label_pos(pos, x_shift=0.05, y_shift=0.05):\n",
        "    \"\"\"Adjusts the positions of the edge labels for better visibility.\n",
        "\n",
        "    Args:\n",
        "        pos: Original position dictionary for nodes.\n",
        "        x_shift: Amount to shift the label along the x-axis.\n",
        "        y_shift: Amount to shift the label along the y-axis.\n",
        "    Returns:\n",
        "        A new dictionary with adjusted label positions.\n",
        "    \"\"\"\n",
        "    pos_labels = {}\n",
        "    for key, value in pos.items():\n",
        "        pos_labels[key] = (value[0] + x_shift, value[1] + y_shift)\n",
        "    return pos_labels\n",
        "\n",
        "# Adjust label positions based on your graph's layout\n",
        "pos_labels = adjust_label_pos(pos, x_shift=0.1, y_shift=0)  # Adjust x_shift and y_shift as needed\n",
        "\n",
        "# Drawing the graph\n",
        "nx.draw(G, with_labels=True, pos=pos, node_color='lightblue', edge_color='gray', node_size=1500, font_size=8)\n",
        "\n",
        "# To show weights with adjusted positions\n",
        "edge_labels = nx.get_edge_attributes(G, 'weight')\n",
        "nx.draw_networkx_edge_labels(G, pos_labels, edge_labels=edge_labels, font_size=7)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Az27ZC6-dvU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.out_edges()"
      ],
      "metadata": {
        "id": "IPsXL3pyFHNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.in_edges()"
      ],
      "metadata": {
        "id": "8dZLwAv9FKZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.degree(weight='weight')"
      ],
      "metadata": {
        "id": "qLiFeRP8GTof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.in_degree(weight='weight')"
      ],
      "metadata": {
        "id": "ULAI1HrmBGUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.out_degree(weight='weight')"
      ],
      "metadata": {
        "id": "zvLPDZcWBioc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the net spending on each team\n",
        "net_spending = []\n",
        "for node_in, indegree in G.in_degree(weight='weight'):\n",
        "  for node_out, outdegree in G.out_degree(weight='weight'):\n",
        "    if node_in == node_out:\n",
        "      spending = outdegree - indegree\n",
        "      team = node_in\n",
        "      net_spending.append((team, spending))\n",
        "net_spending"
      ],
      "metadata": {
        "id": "Q3Vft06sBmor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node Importance Analysis (Centrality)"
      ],
      "metadata": {
        "id": "8Sqr51joRKqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "closeness_centrality = nx.closeness_centrality(G)\n",
        "harmonic_centrality = nx.harmonic_centrality(G)\n",
        "betweenness_centrality = nx.betweenness_centrality(G)\n",
        "eigenvector_centrality = nx.eigenvector_centrality(G)\n",
        "degree_centrality = nx.degree_centrality(G)\n",
        "\n",
        "centrality_measures = pd.DataFrame({\n",
        "    'Team': list(G.nodes()),\n",
        "    'Closeness Centrality': list(closeness_centrality.values()),\n",
        "    'Harmonic Centrality': list(harmonic_centrality.values()),\n",
        "    'Betweenness Centrality': list(betweenness_centrality.values()),\n",
        "    'Eigenvector Centrality': list(eigenvector_centrality.values()),\n",
        "    'Degree Centrality': list(degree_centrality.values())\n",
        "})\n",
        "print(\"Centrality Measures:\")\n",
        "print(centrality_measures.to_string(index=False))"
      ],
      "metadata": {
        "id": "QEZcZC6yRRw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_closeness = centrality_measures.loc[centrality_measures['Closeness Centrality'].idxmax()]\n",
        "best_harmonic = centrality_measures.loc[centrality_measures['Harmonic Centrality'].idxmax()]\n",
        "best_betweenness = centrality_measures.loc[centrality_measures['Betweenness Centrality'].idxmax()]\n",
        "best_eigenvector = centrality_measures.loc[centrality_measures['Eigenvector Centrality'].idxmax()]\n",
        "best_degree = centrality_measures.loc[centrality_measures['Degree Centrality'].idxmax()]\n",
        "print(f\"\\nCloseness Centrality:\\nTeam: {best_closeness['Team']}\\nValue: {best_closeness['Closeness Centrality']:.4f}\")\n",
        "print(f\"\\nHarmonic Centrality:\\nTeam: {best_harmonic['Team']}\\nValue: {best_harmonic['Harmonic Centrality']:.4f}\")\n",
        "print(f\"\\nBetweenness Centrality:\\nTeam: {best_betweenness['Team']}\\nValue: {best_betweenness['Betweenness Centrality']:.4f}\")\n",
        "print(f\"\\nEigenvector Centrality:\\nTeam: {best_eigenvector['Team']}\\nValue: {best_eigenvector['Eigenvector Centrality']:.4f}\")\n",
        "print(f\"\\nDegree Centrality:\\nTeam: {best_degree['Team']}\\nValue: {best_degree['Degree Centrality']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ILjHqh6IRRuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_centrality(centrality_measure, title):\n",
        "    teams = centrality_measure['Team']\n",
        "    values = centrality_measure.drop(columns=['Team'])\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.barh(teams, values.values.reshape(-1), color='skyblue')\n",
        "    plt.xlabel('Centrality Value')\n",
        "    plt.title(title)\n",
        "    for index, value in enumerate(values.values.reshape(-1)):\n",
        "        plt.text(value, index, f'{value:.4f}', va='center', ha='left')\n",
        "\n",
        "    plt.show()\n",
        "plot_centrality(centrality_measures[['Team', 'Closeness Centrality']], 'Closeness Centrality')\n",
        "plot_centrality(centrality_measures[['Team', 'Harmonic Centrality']], 'Harmonic Centrality')\n",
        "plot_centrality(centrality_measures[['Team', 'Betweenness Centrality']], 'Betweenness Centrality')\n",
        "plot_centrality(centrality_measures[['Team', 'Eigenvector Centrality']], 'Eigenvector Centrality')\n",
        "plot_centrality(centrality_measures[['Team', 'Degree Centrality']], 'Degree Centrality')\n"
      ],
      "metadata": {
        "id": "v8LIlN_rRRru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3vqtmMIYRRo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yv9pH2AjRRmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Community Detection (Girvan-Newman Algorithm, louvain_communities and infomap)"
      ],
      "metadata": {
        "id": "fM-VXvJAEY0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Community Clustering using Girvan-Newman Algorithm\n",
        "\n",
        "girvan_communities = girvan_newman(G)\n",
        "print(list(girvan_communities))"
      ],
      "metadata": {
        "id": "CZYofndcCFn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the best community with Girvan-Newman Algorithm\n",
        "\n",
        "from networkx.algorithms.community import girvan_newman\n",
        "\n",
        "def optimal_girvan_newman_communities(G):\n",
        "    optimal = None  # the optimal community\n",
        "    max_mod = 0   # community with the highest modularity\n",
        "\n",
        "    for communities in girvan_newman(G):\n",
        "        mod = modularity(G, communities)\n",
        "        if mod > max_mod:\n",
        "            max_mod = mod\n",
        "            optimal_communities = communities\n",
        "\n",
        "    return tuple(optimal_communities), max_mod\n",
        "\n",
        "optimal_girvan_newman_communities, gn_mod = optimal_girvan_newman_communities(G)\n",
        "\n",
        "print(f\"Optimal Girvan-Newman Communities: {optimal_girvan_newman_communities}\")\n"
      ],
      "metadata": {
        "id": "WRXjUcUhGUvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another alternative: louvain_communities as comparison"
      ],
      "metadata": {
        "id": "7q_QvVKIByvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from networkx.algorithms.community import louvain_communities\n",
        "\n",
        "def optimal_louvain_communities(G):\n",
        "    optimal = None  # the optimal community\n",
        "    max_mod = 0   # community with the highest modularity\n",
        "\n",
        "    communities = louvain_communities(G)\n",
        "\n",
        "    mod = modularity(G, communities)\n",
        "    if mod > max_mod:\n",
        "        max_mod = mod\n",
        "        optimal_communities = communities\n",
        "\n",
        "    return tuple(optimal_communities), max_mod\n",
        "\n",
        "optimal_louvain_communities, louvain_mod = optimal_louvain_communities(G)"
      ],
      "metadata": {
        "id": "jIxG3W0WBvby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another alternative: infomap as comparison"
      ],
      "metadata": {
        "id": "tv4MMt-YCAQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install infomap"
      ],
      "metadata": {
        "id": "nUa27F1BCOmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from infomap import Infomap\n",
        "\n",
        "def optimal_infomap_communities(G):\n",
        "    im = Infomap(\"--directed\")\n",
        "\n",
        "    # Create a dictionary mapping node labels to integer IDs\n",
        "    node_to_id = {node: i for i, node in enumerate(G.nodes())}\n",
        "    id_to_node = {i: node for node, i in node_to_id.items()}\n",
        "\n",
        "    # Add nodes and edges to the Infomap object\n",
        "    for node in G.nodes():\n",
        "        im.add_node(node_to_id[node])\n",
        "    for source, target in G.edges():\n",
        "        im.add_link(node_to_id[source], node_to_id[target])\n",
        "\n",
        "    # Run the Infomap algorithm\n",
        "    im.run()\n",
        "\n",
        "    # Extract the communities\n",
        "    communities = {}\n",
        "    for node_id, module_id in im.modules:\n",
        "        if module_id not in communities:\n",
        "            communities[module_id] = []\n",
        "        communities[module_id].append(id_to_node[node_id])\n",
        "\n",
        "    # Convert the communities dictionary to a list of sets\n",
        "    community_list = [set(nodes) for nodes in communities.values()]\n",
        "\n",
        "    # Calculate modularity\n",
        "    mod = modularity(G, community_list)\n",
        "\n",
        "    return community_list, mod\n",
        "\n",
        "optimal_infomap_communities, infomap_mod = optimal_infomap_communities(G)"
      ],
      "metadata": {
        "id": "fRVFQuTTCNCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Partition Quality and Modularity**"
      ],
      "metadata": {
        "id": "qdHBUh4tO-Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_girvan_communities"
      ],
      "metadata": {
        "id": "WkzlWFMyKqHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate partition quality for each partition\n",
        "girvan_cov, girvan_per = partition_quality(G, optimal_girvan_communities)\n",
        "louvain_cov, louvain_per = partition_quality(G, optimal_louvain_communities)\n",
        "infomap_cov, infomap_per = partition_quality(G, optimal_infomap_communities)\n",
        "\n",
        "# Compare partition quality\n",
        "print(\"Girvan-Newman Partition:\")\n",
        "print(f'The coverage of partition is: {girvan_cov:0.3}')\n",
        "print(f'The performance of partition is: {girvan_per:0.3}')\n",
        "print(f'The modularity of partition is: {girvan_mod:0.3}')\n",
        "print()\n",
        "\n",
        "print(\"Louvain Partition:\")\n",
        "print(f'The coverage of partition is: {louvain_cov:0.3}')\n",
        "print(f'The performance of partition is: {louvain_per:0.3}')\n",
        "print(f'The modularity of partition is: {louvain_mod:0.3}')\n",
        "print()\n",
        "\n",
        "print(\"Infomap Partition:\")\n",
        "print(f'The coverage of partition is: {infomap_cov:0.3}')\n",
        "print(f'The performance of partition is: {infomap_per:0.3}')\n",
        "print(f'The modularity of partition is: {infomap_mod:0.3}')\n",
        "print()\n",
        "\n"
      ],
      "metadata": {
        "id": "MrAMafWLPCWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data visualization with different communities**"
      ],
      "metadata": {
        "id": "rgZupQ36Rj7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Color maps for each partition\n",
        "color_map_girvan = []\n",
        "color_map_louvain = []\n",
        "color_map_infomap = []\n",
        "\n",
        "for node in G.nodes:\n",
        "    for i in range(len(optimal_girvan_communities)):\n",
        "        if node in optimal_girvan_communities[i]:\n",
        "            color_map_girvan.append(sns.color_palette('pastel')[i])\n",
        "            break\n",
        "\n",
        "    for i in range(len(optimal_louvain_communities)):\n",
        "        if node in optimal_louvain_communities[i]:\n",
        "            color_map_louvain.append(sns.color_palette('muted')[i])\n",
        "            break\n",
        "\n",
        "    for i in range(len(optimal_infomap_communities)):\n",
        "        if node in optimal_infomap_communities[i]:\n",
        "            color_map_infomap.append(sns.color_palette('bright')[i])\n",
        "            break\n",
        "\n",
        "# Drawing the graph for each partition\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Girvan-Newman partition\n",
        "nx.draw(G, with_labels=True, pos=pos2, node_color=color_map_girvan, edge_color='gray', node_size=1500, font_size=10, ax=ax1)\n",
        "ax1.set_title(\"Girvan-Newman Partition\")\n",
        "\n",
        "# Louvain partition\n",
        "nx.draw(G, with_labels=True, pos=pos2, node_color=color_map_louvain, edge_color='gray', node_size=1500, font_size=10, ax=ax2)\n",
        "ax2.set_title(\"Louvain Partition\")\n",
        "\n",
        "# Infomap partition\n",
        "nx.draw(G, with_labels=True, pos=pos2, node_color=color_map_infomap, edge_color='gray', node_size=1500, font_size=10, ax=ax3)\n",
        "ax3.set_title(\"Infomap Partition\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyGu6WTwIfye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the perfomances of different algorithms"
      ],
      "metadata": {
        "id": "1cbrkoHPDpad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with the partition quality metrics and modularity scores\n",
        "data = {\n",
        "    'Partition': ['Girvan-Newman', 'Louvain', 'Infomap'],\n",
        "    'Coverage': [girvan_cov, louvain_cov, infomap_cov],\n",
        "    'Performance': [girvan_per, louvain_per, infomap_per],\n",
        "    'Modularity': [girvan_mod, louvain_mod, infomap_mod]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set the style and color palette\n",
        "sns.set(style='whitegrid')\n",
        "palette = sns.color_palette('viridis', 3)\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Coverage plot\n",
        "sns.barplot(x='Partition', y='Coverage', data=df, palette=palette, ax=ax1)\n",
        "ax1.set_title('Coverage')\n",
        "ax1.set_ylim(0, 1)\n",
        "\n",
        "# Performance plot\n",
        "sns.barplot(x='Partition', y='Performance', data=df, palette=palette, ax=ax2)\n",
        "ax2.set_title('Performance')\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "# Modularity plot\n",
        "sns.barplot(x='Partition', y='Modularity', data=df, palette=palette, ax=ax3)\n",
        "ax3.set_title('Modularity')\n",
        "ax3.set_ylim(0, 1)\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pBiCj1ffh2ft"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}